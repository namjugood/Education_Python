{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스그룹 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = fetch_20newsgroups(subset='all', random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(news_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  8 12 ...  7  3  9]\n"
     ]
    }
   ],
   "source": [
    "print(news_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 클래스의 값과 분포도 :\n",
      "0     799\n",
      "1     973\n",
      "2     985\n",
      "3     982\n",
      "4     963\n",
      "5     988\n",
      "6     975\n",
      "7     990\n",
      "8     996\n",
      "9     994\n",
      "10    999\n",
      "11    991\n",
      "12    984\n",
      "13    990\n",
      "14    987\n",
      "15    997\n",
      "16    910\n",
      "17    940\n",
      "18    775\n",
      "19    628\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print('target 클래스의 값과 분포도 :')\n",
    "print(pd.Series(news_data.target).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18846,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(news_data.target).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset='train'으로 학습용(Train) 데이터만 추출\n",
    "train_news = fetch_20newsgroups(subset='train', remove=('headers', 'footers', \\\n",
    "                                                        'quotes'), random_state=156)\n",
    "X_train = train_news.data\n",
    "y_train = train_news.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset='test'로 검증용(Test) 데이터만 추출\n",
    "test_news = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'),\\\n",
    "                               random_state=156)\n",
    "X_test = train_news.data\n",
    "y_test = train_news.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습11314, 테스트7532\n"
     ]
    }
   ],
   "source": [
    "print('학습{0}, 테스트{1}'.format(len(train_news.data), len(test_news.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  data에 대한 CountVectorizer 데이터로 transform\n",
    "## 2. target 값들과 함께 머신러닝 객체로 학습\n",
    "## 3. 테스트 데이터들에 대한 예측 & 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 Text의 CountVectorizer Shape :  (11314, 101631)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cnt_vect = CountVectorizer()\n",
    "# CountVectorizer의 fit : 단어추출 취합 및 인덱싱\n",
    "cnt_vect.fit(X_train)\n",
    "# train 데이터에 대한 transform : 빈도수 count 및 좌표 행렬 구성\n",
    "X_train_cnt_vect = cnt_vect.transform(X_train)\n",
    "print('학습 데이터 Text의 CountVectorizer Shape : ', X_train_cnt_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\204\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 객체 생성 -> 학습( train_data & target )\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_cnt_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 Text의 CountVectorizer Shape :  (11314, 101631)\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer의 fit : 단어추출 취합 및 인덱싱\n",
    "# cnt_vect.fit(X_test) -> 실행되는 순간 취합된 자료가 새로운 자료로 구성되어버림\n",
    "# 생략 = 기존 피팅 객체로(cnt_vect)로 transform한다는 말입니다\n",
    "\n",
    "# train 데이터에 대한 transform : 빈도수 count 및 좌표 행렬 구성\n",
    "X_test_cnt_vect = cnt_vect.transform(X_test)\n",
    "print('학습 데이터 Text의 CountVectorizer Shape : ', X_test_cnt_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__주의__\n",
    "* 학습데이터에 대해 fit()된 CountVectorizer를 이용해서 테스트 데이터를 피처 벡터화해야 합니다\n",
    "* 테스트 데이터에서 다시 CountVectorizer의 fit_transform()을 수행하거나 fit()을 수행하면 기존학습데이터의 단어들과 달라진 feature들이 생성되어 기존 학습된 모델에서 가지는 feature의 개수가 달라지며, 머신러닝에 적용할 fit 데이터와 predict 데이터의 형식이 달라지기 때문입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorized Logistic Regression의 예측 정확도는 0.964\n"
     ]
    }
   ],
   "source": [
    "pred = lr_clf.predict(X_test_cnt_vect)\n",
    "print('CountVectorized Logistic Regression의 예측 정확도는 {0:.3f}'.format(\\\n",
    "                                                       accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CounterVectorizer의 업그레이드 버전 TfidVectorizer\n",
    "* 해당 단어의 한 문서당 출현 빈도수와, 해당 단어의 문서 분포도를 fit와 transform의 구성요소로 포함시킨 모델입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 생성\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "# X_train으로 fit\n",
    "tfidf_vect.fit(X_train)\n",
    "# X_train으로 fit된 객체를 이용하여 X_train을 transform\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "# X_train으로 fit된 객체를 이용하여 X_test을 transform\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Logistic Regression의 예측 정확도는 0.907\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression을 이용하여 학습/예측/평가 수행\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_train_tfidf_vect)\n",
    "print('TF-IDF Logistic Regression의 예측 정확도는 {0:.3f}'.format(\\\n",
    "                                                      accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords 추가\n",
    "# ngram을 기본(1,1)에서 (1,2)로 변경\n",
    "# max_df=300 : 300번 이상 출현한 데이터는 추출대상(피쳐)에서 제외\n",
    "# min_df=10 : 10번 이하 출현한 단어는 추출대상에서 제외\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300)\n",
    "\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_clf = LogisticRegression()\n",
    "lf_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression의 예측 정확도(옵션추가) : {0:.3f}'.format(\\\n",
    "                                                      accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사이킷런 파이프라인(Pipeline) 사용 및 GridSearchCV와의 결합\n",
    "### GridSearchCV\n",
    "* 학습과 예측에 영향을 줄 수 있는 파라미터 값들을 여러 값들로 설정하며, 데이터 셋의 분할 또한 횟수만큼 교차 분할하여 여러차례 학습-예측을 반복하는 도구입니다.\n",
    "* 반복학습 및 예측된 모델 중 가장 성능이 좋았던 모델을 실행결과로 선택하여 대표모델로 재학습시켜 실제 예측에 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 하이퍼 파라미터는 머신러닝 모델에 따라 그 종류가 다양하게 사용됩니다\n",
    "# LogisticRegression의 C 파라미터 : 시그모이드함수()의 그래프에서 곡선의 완만함을 조절할 수 있는 조절값\n",
    "params = {'C':[5, 10] }\n",
    "grid_cv_lr = GridSearchCV(lr_clf, param_grid=params, cv=2, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=LogisticRegression(), param_grid={'C': [5, 10]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습\n",
    "grid_cv_lr.fit(X_train_tfidf_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression best C parameter :  {'C': 10}\n",
      "TF-IDF Vectorized Logistic Regression(GridSearchCV)의 정확도 : 0.973\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "pred = grid_cv_lr.predict(X_test_tfidf_vect)\n",
    "print('Logistic Regression best C parameter : ', grid_cv_lr.best_params_)\n",
    "print('TF-IDF Vectorized Logistic Regression(GridSearchCV)의 정확도 : {0:.3f}'\\\n",
    "      .format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "* pipeline 함수의 기능을 이용하여 두 개의 동작(Tfidvectorizor의 fit와 transform, LogisticRegression의 fit과 predict를 순서대로 실행\n",
    "* 파이프라인에 순서대로 들어가 있기 대문에 별도의 Tfidvectorizor 객체의 fit(), transform() 그리고 별도의 LogsticRegression의 fit()과 predict()가 필요없습니다\n",
    "* pipeline의 fit()과 predict()만으로도 한꺼번에 Feature Vectorization과 머신러닝학습 및 예측이 가능합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline & TF-IDF Vectorized Logistic Regression의 예측 정확도 : 0.973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# 파이프라인 구성 및 객체 생성\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english', ngram_range=(1,2), \\\n",
    "                                 max_df=300)),\n",
    "    ('lr_clf', LogisticRegression(C=10))\n",
    "])\n",
    "# fit와 predict 함수로 Feature Vectorization과 머신러닝 fit, predict를 순서대로 실행\n",
    "pipeline.fit(X_train, y_train)\n",
    "pred = pipeline.predict(X_test)\n",
    "print('Pipeline & TF-IDF Vectorized Logistic Regression의 예측 정확도 : {0:.3f}'\\\n",
    "                                            .format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer(stop_words='english')),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])\n",
    "# pipeline에 기술된 각각의 객체 변수에 언더바(_) 2개를 연달아 붙여 GridSearchCV에\n",
    "# 사용될 파라미터/하이퍼 파라미터 이름과 값을 설정\n",
    "params = { 'tfidf_vect__ngram_range':[ (1,1), (1,2) ],\n",
    "           'tfidf_vect__max_df': [100, 300],\n",
    "           'lr_clf__C': [10]\n",
    "         }\n",
    "# 파이프라인 생성 후\n",
    "# GridSearchCV의 생성자에 Estimator가 아닌 Pipeline 객체 입력\n",
    "grid_cv_pipe = GridSearchCV( pipeline, param_grid=params, cv=3, \\\n",
    "                                       scoring='accuracy', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'fix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-ce2c5a55000e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_cv_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_cv_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_cv_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'fix'"
     ]
    }
   ],
   "source": [
    "grid_cv_pipe.fix(X_train, y_train)\n",
    "print(grid_cv_pipe.best_params_, grid_cv_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = grid_cv_pipe.predict(X_test)\n",
    "print('Pipeline을 통한 Logistic Regression의 예측 정확도는 {0:.3f}'\\\n",
    "                                 .format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
