{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비 지도 학습 기반 감성 분석 소개\n",
    "## SentiWordNet을 이용한 Sentiment Analysis\n",
    "* WordNet Synset과 SentiWordNet SentiSynset 클래스의 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synsets() 반환 type :  <class 'list'>\n",
      "synsets() 반환 값 개수 :  7\n",
      "synsets() 반환 값 :  [Synset('sun.n.01'), Synset('sunlight.n.01'), Synset('sun.n.03'), Synset('sun.n.04'), Synset('sunday.n.01'), Synset('sun.v.01'), Synset('sun.v.02')]\n"
     ]
    }
   ],
   "source": [
    "term = 'sun'\n",
    "# 'present'라는 단어로 wordnet의 synsets(단어의 의미와 구성 및 품사, 유사어 등을 \n",
    "# 저장하고 있는 객체)생성\n",
    "synsets = wn.synsets(term)\n",
    "print('synsets() 반환 type : ', type(synsets))\n",
    "print('synsets() 반환 값 개수 : ', len(synsets))\n",
    "print('synsets() 반환 값 : ', synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### synset 이름 :  sun.n.01 ####\n",
      "POS :  noun.object\n",
      "Definition: the star that is the source of light and heat for the planets in the solar system\n",
      "Lemmas: ['sun', 'Sun']\n",
      "#### synset 이름 :  sunlight.n.01 ####\n",
      "POS :  noun.phenomenon\n",
      "Definition: the rays of the sun\n",
      "Lemmas: ['sunlight', 'sunshine', 'sun']\n",
      "#### synset 이름 :  sun.n.03 ####\n",
      "POS :  noun.person\n",
      "Definition: a person considered as a source of warmth or energy or glory etc\n",
      "Lemmas: ['sun']\n",
      "#### synset 이름 :  sun.n.04 ####\n",
      "POS :  noun.object\n",
      "Definition: any star around which a planetary system revolves\n",
      "Lemmas: ['sun']\n",
      "#### synset 이름 :  sunday.n.01 ####\n",
      "POS :  noun.time\n",
      "Definition: first day of the week; observed as a day of rest and worship by most Christians\n",
      "Lemmas: ['Sunday', \"Lord's_Day\", 'Dominicus', 'Sun']\n",
      "#### synset 이름 :  sun.v.01 ####\n",
      "POS :  verb.body\n",
      "Definition: expose one's body to the sun\n",
      "Lemmas: ['sun', 'sunbathe']\n",
      "#### synset 이름 :  sun.v.02 ####\n",
      "POS :  verb.perception\n",
      "Definition: expose to the rays of the sun or affect by exposure to the sun\n",
      "Lemmas: ['sun', 'insolate', 'solarize', 'solarise']\n"
     ]
    }
   ],
   "source": [
    "for synset in synsets:\n",
    "    print('#### synset 이름 : ', synset.name(),'####')  # 해당 단어\n",
    "    print('POS : ', synset.lexname())  # 해당의 형태(명사 동사 등)\n",
    "    print('Definition:', synset.definition())  # 해당 단어의 정의\n",
    "    print('Lemmas:', synset.lemma_names()) # 해당 단어의 유사어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a tall perennial woody plant having a main trunk and branches forming a distinct elevated crown; includes both gymnosperms and angiosperms\n",
      "\n",
      "large feline of forests in most of Asia having a tawny coat with black stripes; endangered\n"
     ]
    }
   ],
   "source": [
    "#synset 객체를 단어별로 생성합니다\n",
    "tree = wn.synset('tree.n.01')\n",
    "lion = wn.synset('lion.n.01')\n",
    "tiger = wn.synset('tiger.n.02')\n",
    "cat = wn.synset('cat.n.01')\n",
    "dog = wn.synset('dog.n.01')\n",
    "print(tree.definition())\n",
    "print()\n",
    "print(tiger.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree.n.01\n"
     ]
    }
   ],
   "source": [
    "print(tree.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree\n"
     ]
    }
   ],
   "source": [
    "print(tree.name().split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tree', 'lion', 'tiger', 'cat', 'dog']\n"
     ]
    }
   ],
   "source": [
    "entities = [tree, lion, tiger, cat, dog]\n",
    "entity_names = [ entity.name().split('.')[0] for entity in entities]\n",
    "print(entity_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print(entities[1].path_similarity(entities[2],2))\n",
    "# 각 단어끼리의 유사성 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 0.07, 0.07, 0.08, 0.12], [0.07, 1.0, 0.33, 0.25, 0.17], [0.07, 0.33, 1.0, 0.25, 0.17], [0.08, 0.25, 0.25, 1.0, 0.2], [0.12, 0.17, 0.17, 0.2, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "# entities[0]으로 전체 데이터와 유사도 측정 : 결과가 리스트\n",
    "# entities[1]으로 전체 데이터와 유사도 측정 : 결과가 리스트\n",
    "# entities[2]으로 전체 데이터와 유사도 측정 : 결과가 리스트\n",
    "# entities[3]으로 전체 데이터와 유사도 측정 : 결과가 리스트\n",
    "# entities[4]으로 전체 데이터와 유사도 측정 : 결과가 리스트\n",
    "# 결과 리스트들을 별도의 리스트에 appned\n",
    "similarities = []\n",
    "for en1 in entities:\n",
    "    similarity = [round(en1.path_similarity(en2), 2) for en2 in entities]\n",
    "    similarities.append(similarity)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>lion</th>\n",
       "      <th>tiger</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lion</th>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tree  lion  tiger   cat   dog\n",
       "tree   1.00  0.07   0.07  0.08  0.12\n",
       "lion   0.07  1.00   0.33  0.25  0.17\n",
       "tiger  0.07  0.33   1.00  0.25  0.17\n",
       "cat    0.08  0.25   0.25  1.00  0.20\n",
       "dog    0.12  0.17   0.17  0.20  1.00"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_df = pd.DataFrame(similarities, columns=entity_names, index=entity_names)\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.corpus import sentiwordnet as swn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "father 긍정감성 지수 : 0.0\n",
      "father 부정감성 지수 : 0.0\n",
      "father 객관성 지수 : 1.0\n",
      "\n",
      "fabulous 긍정감성 지수 : 0.875\n",
      "fabulous 부정감성 지수 : 0.125\n",
      "fabulous 객관성 지수 : 0.0\n"
     ]
    }
   ],
   "source": [
    "father = swn.senti_synset('father.n.01')\n",
    "print('father 긍정감성 지수 :', father.pos_score())\n",
    "print('father 부정감성 지수 :', father.neg_score())\n",
    "print('father 객관성 지수 :', father.obj_score())\n",
    "print()\n",
    "fabulous = swn.senti_synset('fabulous.a.01')\n",
    "print('fabulous 긍정감성 지수 :', fabulous.pos_score())\n",
    "print('fabulous 부정감성 지수 :', fabulous.neg_score())\n",
    "print('fabulous 객관성 지수 :', fabulous.obj_score())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "# pos_tag : 입력단어에 세부품사를 추출하는 모듈\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비 지도학습 기반 감성 분석 실습 - IMDB 영화평"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "review_df = pd.read_csv('./labeledTrainData.tsv', header=0, sep='\\t', quoting=3)\n",
    "review_df['review'] = review_df['review'].str.replace('<br />',' ')\n",
    "review_df['review'] = review_df['review'].apply(lambda x:re.sub('[^a-zA-Z]',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "class_df = review_df['sentiment']  # target 분리\n",
    "feature_df = review_df.drop(['id', 'sentiment'], axis=1, inplace=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_df, class_df, \\\n",
    "                                                   test_size=0.3, random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 품사태그를 전달받아서 해당 품사객체를 리턴하는 함수 제작\n",
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('J'):  # 형용사\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'): # 명사\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'): # 부사\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'): # 동사\n",
    "        return wn.VERB\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장을 전달인수로 받고, 부정감성지수와 긍정감성지수의 연산으로 결정된\n",
    "# 0 또는 1을 리턴하는 함수 제작\n",
    "def swn_polarity(text):   # text에는 문장이 전달 : review_df['review'][0]\n",
    "    # 0 또는 1의 값을 결정할 감성지수를 저장할 변수 생성  초기화\n",
    "    sentiment = 0.0\n",
    "    tokens_count = 0\n",
    "    \n",
    "    # 단어의 원형을 찾아줄 객체 생성\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # 전달된 text를 문장별로 분리\n",
    "    raw_sentences = sent_tokenize(text)\n",
    "    # print(raw_sentences)  # test code\n",
    "    for rs in raw_sentences:\n",
    "        ts = pos_tag(word_tokenize(rs))\n",
    "        for word, tag in ts:\n",
    "            wn_tag = penn_to_wn(tag)\n",
    "            #print(wn_tag)  # test code\n",
    "            if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
    "                continue  # 명사 형용사 동사 아니면 다음반복 : 분석에 필요없는 품사 제외\n",
    "            # 단어의 어근(표준형) 추출\n",
    "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "            # 어근을 추출한 단어와 WordNet 기반 품사 태깅을 입력해 synset 객체를 생성\n",
    "            synsets = wn.synsets(lemma, pos=wn_tag)\n",
    "            if not synsets:  # 생성한 synset 리스트가 비었으면 다음\n",
    "                continue\n",
    "            # print(synsets)  # test code\n",
    "            # sentiwordnet의 감성 단어 분석으로 감성 synset 추출\n",
    "            # 모든 단어에 대해 긍정 감성 지수는 +로\n",
    "            # 부정 감성 지수는 -로 합산해 감성 지수 계산\n",
    "            synset = synsets[0]\n",
    "            swn_synset = swn.senti_synset(synset.name())\n",
    "            sentiment += (swn_synset.pos_score() - swn_synset.neg_score())\n",
    "            tokens_count += 1\n",
    "    if not tokens_count:\n",
    "        return 0\n",
    "    # 총 score가 0 이상일 경우 긍정(Positive) 1, 그렇지 않으면 부정(Negative) 0\n",
    "    if sentiment >= 0 :\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NNP : 단수 고유명사\n",
    "* VB : 동사\n",
    "* VBP : 동사 현재형\n",
    "* TO : to 전치사\n",
    "* NN : 명사\n",
    "* DT : 관형사\n",
    "* RB : 부사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swn_polarity(review_df['review'][0])  # test code\n",
    "review_df['preds'] = review_df['review'].apply(lambda x : swn_polarity(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = review_df['sentiment'].values # 실제값\n",
    "preds = review_df['preds'].values # 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7668 4832]\n",
      " [3636 8864]]\n",
      "정확도 : 0.66128\n",
      "정밀도 : 0.647196261682243\n",
      "재현율 : 0.70912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_scorecoreuracy_score, confusion_matrix, precision_score\n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
    "\n",
    "print(\"오차행렬 : \")\n",
    "print(confusion_matrix(y_target, preds))\n",
    "print(\"정확도 :\", accuracy_score(y_target, preds))\n",
    "print(\"정밀도 :\", precision_score(y_target, preds))\n",
    "print(\"재현율 :\", recall_score(y_target, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.061, 'neu': 0.866, 'pos': 0.072, 'compound': 0.4893}\n"
     ]
    }
   ],
   "source": [
    "senti_analyzer = SentimentIntensityAnalyzer()\n",
    "senti_scores = senti_analyzer.polarity_scores(review_df['review'][3])\n",
    "print(senti_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_polarity(review, threshold=0.1):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    \n",
    "    # compound 값에 기반하여 threshold 입력값보다 크면 1, 그렇지 않으면 0을 반환\n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 1 if agg_score >= threshold else 0\n",
    "    # threshold : 0과 1의 임계점, 경계선\n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['vader_preds'] = review_df['review'].apply(lambda x : vader_polarity(x, 0.1))\n",
    "y_target = review_df['sentiment'].values\n",
    "vader_preds = review_df['vader_preds'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### VADER 예측 성능 평가 ####\n",
      "[[ 6729  5771]\n",
      " [ 1858 10642]]\n",
      "정확도 : 0.69484\n",
      "정밀도 : 0.6483884725522452\n",
      "재현율 : 0.85136\n"
     ]
    }
   ],
   "source": [
    "print('#### VADER 예측 성능 평가 ####')\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
    "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
    "print(confusion_matrix(y_target, vader_preds))\n",
    "print(\"정확도 :\", accuracy_score(y_target, vader_preds))\n",
    "print(\"정밀도 :\", precision_score(y_target, vader_preds))\n",
    "print(\"재현율 :\", recall_score(y_target, vader_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
