{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스그룹 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = fetch_20newsgroups(subset='all', random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(news_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  8 12 ...  7  3  9]\n"
     ]
    }
   ],
   "source": [
    "print(news_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 클래스의 값과 분포도 :\n",
      "0     799\n",
      "1     973\n",
      "2     985\n",
      "3     982\n",
      "4     963\n",
      "5     988\n",
      "6     975\n",
      "7     990\n",
      "8     996\n",
      "9     994\n",
      "10    999\n",
      "11    991\n",
      "12    984\n",
      "13    990\n",
      "14    987\n",
      "15    997\n",
      "16    910\n",
      "17    940\n",
      "18    775\n",
      "19    628\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print('target 클래스의 값과 분포도 :')\n",
    "print(pd.Series(news_data.target).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18846,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(news_data.target).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset='train'으로 학습용(Train) 데이터만 추출\n",
    "train_news = fetch_20newsgroups(subset='train', remove=('headers', 'footers', \\\n",
    "                                                        'quotes'), random_state=156)\n",
    "X_train = train_news.data\n",
    "y_train = train_news.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset='test'로 검증용(Test) 데이터만 추출\n",
    "test_news = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'),\\\n",
    "                               random_state=156)\n",
    "X_test = train_news.data\n",
    "y_test = train_news.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습11314, 테스트7532\n"
     ]
    }
   ],
   "source": [
    "print('학습{0}, 테스트{1}'.format(len(train_news.data), len(test_news.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  data에 대한 CountVectorizer 데이터로 transform\n",
    "## 2. target 값들과 함께 머신러닝 객체로 학습\n",
    "## 3. 테스트 데이터들에 대한 예측 & 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 Text의 CountVectorizer Shape :  (11314, 101631)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cnt_vect = CountVectorizer()\n",
    "# CountVectorizer의 fit : 단어추출 취합 및 인덱싱\n",
    "cnt_vect.fit(X_train)\n",
    "# train 데이터에 대한 transform : 빈도수 count 및 좌표 행렬 구성\n",
    "X_train_cnt_vect = cnt_vect.transform(X_train)\n",
    "print('학습 데이터 Text의 CountVectorizer Shape : ', X_train_cnt_vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\204\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 객체 생성 -> 학습( train_data & target )\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_cnt_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 Text의 CountVectorizer Shape :  (11314, 101631)\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer의 fit : 단어추출 취합 및 인덱싱\n",
    "# cnt_vect.fit(X_test) -> 실행되는 순간 취합된 자료가 새로운 자료로 구성되어버림\n",
    "# 생략 = 기존 피팅 객체로(cnt_vect)로 transform한다는 말입니다\n",
    "\n",
    "# train 데이터에 대한 transform : 빈도수 count 및 좌표 행렬 구성\n",
    "X_test_cnt_vect = cnt_vect.transform(X_test)\n",
    "print('학습 데이터 Text의 CountVectorizer Shape : ', X_test_cnt_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__주의__\n",
    "* 학습데이터에 대해 fit()된 CountVectorizer를 이용해서 테스트 데이터를 피처 벡터화해야 합니다\n",
    "* 테스트 데이터에서 다시 CountVectorizer의 fit_transform()을 수행하거나 fit()을 수행하면 기존학습데이터의 단어들과 달라진 feature들이 생성되어 기존 학습된 모델에서 가지는 feature의 개수가 달라지며, 머신러닝에 적용할 fit 데이터와 predict 데이터의 형식이 달라지기 때문입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorized Logistic Regression의 예측 정확도는 0.964\n"
     ]
    }
   ],
   "source": [
    "pred = lr_clf.predict(X_test_cnt_vect)\n",
    "print('CountVectorized Logistic Regression의 예측 정확도는 {0:.3f}'.format(\\\n",
    "                                                       accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CounterVectorizer의 업그레이드 버전 TfidVectorizer\n",
    "* 해당 단어의 한 문서당 출현 빈도수와, 해당 단어의 문서 분포도를 fit와 transform의 구성요소로 포함시킨 모델입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 객체 생성\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "# X_train으로 fit\n",
    "tfidf_vect.fit(X_train)\n",
    "# X_train으로 fit된 객체를 이용하여 X_train을 transform\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "# X_train으로 fit된 객체를 이용하여 X_test을 transform\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Logistic Regression의 예측 정확도는 0.907\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression을 이용하여 학습/예측/평가 수행\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_train_tfidf_vect)\n",
    "print('TF-IDF Logistic Regression의 예측 정확도는 {0:.3f}'.format(\\\n",
    "                                                      accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords 추가\n",
    "# ngram을 기본(1,1)에서 (1,2)로 변경\n",
    "# max_df=300 : 300번 이상 출현한 데이터는 추출대상(피쳐)에서 제외\n",
    "# min_df=10 : 10번 이하 출현한 단어는 추출대상에서 제외\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=300)\n",
    "\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 943453 features per sample; expecting 101631",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-121ae44548e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlf_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlf_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tfidf_vect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tfidf_vect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m print('TF-IDF Vectorized Logistic Regression의 예측 정확도(옵션추가) : {0:.3f}'.format(\\\n\u001b[0;32m      5\u001b[0m                                                       accuracy_score(y_test, pred)))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \"\"\"\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[0;32m    287\u001b[0m                              % (X.shape[1], n_features))\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 943453 features per sample; expecting 101631"
     ]
    }
   ],
   "source": [
    "lf_clf = LogisticRegression()\n",
    "lf_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_train_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression의 예측 정확도(옵션추가) : {0:.3f}'.format(\\\n",
    "                                                      accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사이킷런 파이프라인(Pipeline) 사용 및 GridSearchCV와의 결합\n",
    "### GridSearchCV\n",
    "* 학습과 예측에 영향을 줄 수 있는 파라미터 값들을 여러 값들로 설정하며, 데이터 셋의 분할 또한 횟수만큼 교차 분할하여 여러차례 학습-예측을 반복하는 도구입니다.\n",
    "* 반복학습 및 예측된 모델 중 가장 성능이 좋았던 모델을 실행결과로 선택하여 대표모델로 재학습시켜 실제 예측에 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 하이퍼 파라미터는 머신러닝 모델에 따라 그 종류가 다양하게 사용됩니다\n",
    "# LogisticRegression의 C 파라미터 : 시그모이드함수()의 그래프에서 곡선의 완만함을 조절할 수 있는 조절값\n",
    "params = {'C':[5, 10] }\n",
    "grid_cv_lr = GridSearchCV(lr_clf, param_grid=params, cv=2, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "grid_cv_lr.fit(X_train_tfidf_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측\n",
    "pred = grid_lr_clf.predict(X_test_tfidf_vect)\n",
    "print('Logistic Regression best C parameter : ', grid_cv_lr.best_params_)\n",
    "print('TF-IDF Vectorized Logistic Regression(GridSearchCV)의 정확도 : {0:.3f}'\\\n",
    "      .format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "* pipeline 함수의 기능을 이용하여 두 개의 동작(Tfidvectorizor의 fit와 transform, LogisticRegression의 fit과 predict를 순서대로 실행\n",
    "* 파이프라인에 순서대로 들어가 있기 대문에 별도의 Tfidvectorizor 객체의 fit(), transform() 그리고 별도의 LogsticRegression의 fit()과 predict()가 필요없습니다\n",
    "* pipeline의 fit()과 predict()만으로도 한꺼번에 Feature Vectorization과 머신러닝학습 및 예측이 가능합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 구성 및 객체 생성\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidVectorizer(stop_words='english', ngram_range=(1,2), \\\n",
    "                                 max_df=300)),\n",
    "    ('lr_clf', LogisticRegression(C=10))\n",
    "])\n",
    "# fit와 predict 함수로 Feature Vectorization과 머신러닝 fit, predict를 순서대로 실행\n",
    "pipeline.fit(X_train, y_train)\n",
    "pred = pipeline.predict(X_test)\n",
    "prin('Pipeline & TF-IDF Vectorized Logistic Regression의 예측 정확도 : {0:.3f}'\\\n",
    "                                            .format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
